{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos en la carpeta raw: ['test.csv', 'train.csv', 'transactions.csv', 'oil.csv', 'holidays_events.csv', 'sample_submission.csv', 'stores.csv']\n",
      "Los valores nulos en holidays.date son: 0\n",
      " HOLIDAY: RANGO DE FECHAS DE 2012-03-02 00:00:00 a 2017-12-26 00:00:00\n",
      "Los datos iniciales son: 350 los que hemos quitado 12 los que nos quedan 338  \n",
      "Los valores nulos en oil.date son: 0\n",
      "Los valores nulos en stores.store_nbr son: 0\n",
      "Los valores nulos en transactions.store_nbr son: 0\n",
      "Los valores nulos en transactions.date son: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Ruta desde notebooks/ hacia los CSV\n",
    "data_path = \"../data/raw/\"\n",
    "\n",
    "# Listar archivos para confirmar que encuentra los CSV\n",
    "archivos = os.listdir(data_path)\n",
    "print(\"Archivos en la carpeta raw:\", archivos)\n",
    "\n",
    "\n",
    "\n",
    "#HOLIDAYS_EVENTS\n",
    "holiday_df = pd.read_csv(os.path.join(data_path, \"holidays_events.csv\"))\n",
    "\n",
    "#CONTROL DE FECHAS HOLIDAY\n",
    "\n",
    "holiday_df[\"date\"] = pd.to_datetime(holiday_df[\"date\"])\n",
    "\n",
    "fecha_min = holiday_df[\"date\"].min()\n",
    "fecha_max = holiday_df[\"date\"].max()\n",
    " \n",
    "nulos_date_holidays = holiday_df[\"date\"].isnull().sum()\n",
    "\n",
    "print(f\"Los valores nulos en holidays.date son: {nulos_date_holidays}\")\n",
    "print(f\" HOLIDAY: RANGO DE FECHAS DE {fecha_min} a {fecha_max}\")\n",
    "\n",
    "\n",
    "holiday_df[\"date\"] = pd.to_datetime(holiday_df[\"date\"])  # Asegurar que es datetime\n",
    "holiday_df[\"year\"] = holiday_df[\"date\"].dt.year\n",
    "holiday_df[\"month\"] = holiday_df[\"date\"].dt.month\n",
    "holiday_df[\"day\"] = holiday_df[\"date\"].dt.day\n",
    "holiday_df[\"day_of_week\"] = holiday_df[\"date\"].dt.weekday  # 0 = Lunes, 6 = Domingo\n",
    "holiday_df[\"week_of_year\"] = holiday_df[\"date\"].dt.isocalendar().week  # Semana del año\n",
    "\n",
    "#LIMPIEZA DE LA COLUMNA TRANSFERRED:\n",
    "\n",
    "# Filtrar solo los registros donde transferred == False (es decir, NO transferidos)\n",
    "holiday_df_clean = holiday_df[holiday_df.transferred == False]\n",
    "\n",
    "# Eliminar la columna transferred, ya que ahora es innecesaria\n",
    "holiday_df_clean = holiday_df_clean.drop(\"transferred\", axis=1)\n",
    "\n",
    "# Reiniciar el índice tras la limpieza\n",
    "holiday_df_clean = holiday_df_clean.reset_index(drop=True)\n",
    "\n",
    "#COMPROBACIÓN DE QUE ES CORRECTA\n",
    "\n",
    "datos_iniciales = holiday_df.shape[0]\n",
    "\n",
    "datosSinTransferred= holiday_df[holiday_df[\"transferred\"] != False].shape[0]\n",
    "\n",
    "\n",
    "holiday_df_clean = holiday_df[holiday_df[\"transferred\"] == False]\n",
    "\n",
    "datos_postFiltrado = holiday_df_clean.shape[0]\n",
    "\n",
    "print(f\"Los datos iniciales son: {datos_iniciales} los que hemos quitado {datosSinTransferred} los que nos quedan {datos_postFiltrado}  \")\n",
    "\n",
    "\n",
    "#OIL \n",
    "\n",
    "# Cargar y mostrar las primeras filas del archivo oil.csv\n",
    "oil_df = pd.read_csv(os.path.join(data_path, \"oil.csv\"))\n",
    "\n",
    "oil_df[\"date\"] = pd.to_datetime(oil_df[\"date\"])\n",
    "\n",
    "#HAY NULOS EN DATE?\n",
    "\n",
    "nulos_date_oil = oil_df[\"date\"].isnull().sum()\n",
    "\n",
    "print(f\"Los valores nulos en oil.date son: {nulos_date_oil}\")\n",
    "\n",
    "\n",
    "# STORES\n",
    "stores = pd.read_csv(os.path.join(data_path, \"stores.csv\"))\n",
    "\n",
    "store_nbr = stores[\"store_nbr\"].isnull().sum()\n",
    "\n",
    "print(f\"Los valores nulos en stores.store_nbr son: {store_nbr}\")\n",
    "\n",
    "\n",
    "#Transactions\n",
    "\n",
    "transactions = pd.read_csv(os.path.join(data_path, \"transactions.csv\"))\n",
    "\n",
    "transactions[\"date\"] = pd.to_datetime(transactions[\"date\"])\n",
    "\n",
    "transactions_storenbr = transactions[\"store_nbr\"].isnull().sum()\n",
    "transactions_date = transactions[\"date\"].isnull().sum()\n",
    "\n",
    "print(f\"Los valores nulos en transactions.store_nbr son: {transactions_storenbr}\")\n",
    "print(f\"Los valores nulos en transactions.date son: {transactions_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SÓLO ES UN NOTEBOOK HAY QUE PASARLO A SCRIPT CON RAISERROR PARA NO PERDER IDs Y RELACIÓN\n",
    "### Relaciones entre los 4 datasets, PASOS PARA JUNTAR orígenes:\n",
    "#### 1.transactions con store ---> store_nbr   NUEVO DF store_transaction\n",
    "#### holiday con oil con store_transaction --> date\n",
    "\n",
    "## HACER RAISE ERROR EN UN SCRIPT DE LOS IDs para asegurar la BBDD\n",
    "## CREAR BBDD y su estructura\n",
    "## Generar inserts if not exists desde el script de raiseError\n",
    "## Explotar la BBDD y sacar una view que sea nuestro próximo csv para el modelo ya bien tratado.\n",
    "\n",
    "\n",
    "\n",
    "# \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
